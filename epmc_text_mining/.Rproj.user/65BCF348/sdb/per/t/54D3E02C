{
    "contents" : "---\ntitle: Evaluation text mining predictions EPMC\ndate: 2016-03-31\nauthor: Pablo Porras\n---\n```{r set-options, echo=FALSE}\noptions(width = 80)\n```\n```{r echo=FALSE}\n# Multiple plot function\n#\n# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)\n# - cols:   Number of columns in layout\n# - layout: A matrix specifying the layout. If present, 'cols' is ignored.\n#\n# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),\n# then plot 1 will go in the upper left, 2 will go in the upper right, and\n# 3 will go all the way across the bottom.\n#\nmultiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {\n  library(grid)\n\n  # Make a list from the ... arguments and plotlist\n  plots <- c(list(...), plotlist)\n\n  numPlots = length(plots)\n\n  # If layout is NULL, then use 'cols' to determine layout\n  if (is.null(layout)) {\n    # Make the panel\n    # ncol: Number of columns of plots\n    # nrow: Number of rows needed, calculated from # of cols\n    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),\n                    ncol = cols, nrow = ceiling(numPlots/cols))\n  }\n\n if (numPlots==1) {\n    print(plots[[1]])\n\n  } else {\n    # Set up the page\n    grid.newpage()\n    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))\n\n    # Make each plot, in the correct location\n    for (i in 1:numPlots) {\n      # Get the i,j matrix positions of the regions that contain this subplot\n      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))\n\n      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,\n                                      layout.pos.col = matchidx$col))\n    }\n  }\n}\n```\nText mining prediction EPMC: Technical report\n========================================================\n\n### Synopsis\n\nWe collaborated the EPMC team at EBI to use text-mining techniques that use a set of keywords (see Appendix) that describe potential interaction relationships to identify sentences that may depict interacting proteins. The sentences are extracted from the abstract or full text (when available, due to copyright restrictions) or publications listed in PubMed. The text-mining exercise was performed by Senay Kafkas (SK). Email exchange about this subject can be found in the folder ./source_files/emails. \n\n\n### Part 1: Evaluate and extract information from SK file\n\nSK sent the result file from her search script on 2015/08/28 and an updated version with all PMIDs added on 2016/04/07. Here is the text of the email she sent on the first instance:  \n\n*\"I now adapted our gene-disease pipeline which we developed for the cttv project, for extracting the PPIs. I used the keyword list that we agreed on before.*  \n\n*The data that I generated is big, hence I cannot attach it to the e-mail, but you can access it from:*\n\n*/nfs/misc/literature/shenay/PPIExtraction/PPIData4Expr.txt*\n\n*I provided the data in the format that we provide for the cttv project. The first line in the file describes the data format which is not complicated to understand. One thing is I provided only 3 publication IDs and sentences. However if you would need all of the publications and sentences, I can extract this data easily as well.\"*\n\nIt is important to note that the data contains human identifiers only. \n\n#### Estimating file size and memory requirements\n\nThe file sent by SK is too big to be loaded in R, so I process first a sample to have a look at the data.\n\n```{r eval=FALSE}\n# The files used here are over 1GB and not suitable to be loaded in github. They are  available upon request. \nsystem(\"tar -xzf ./source_files/PPIData4Expr_noLimit.tar.gz -C ./source_files/\")\nsystem(\"touch ./processed_files/PPIData4Expr_noLimit_sample.txt\")\nsystem(\"sed -n '1,1000 p' ./source_files/PPIData4Expr_noLimit.txt > ./processed_files/PPIData4Expr_noLimit_sample.txt\")\n```\n```{r comment=NA}\nppi_sample <- read.delim(\"./processed_files/PPIData4Expr_noLimit_sample.txt\", sep=\"\\t\",header=T,quote=\"\\\"\")\nhead(ppi_sample)\n```\n\nIt seems that the sentence fields are very large and make the file extremely big. I check to see if I have enough memory to load the table. \n\n```{r eval=T,cache=TRUE}\ntop.size <- object.size(read.delim(\"./processed_files/PPIData4Expr_noLimit_sample.txt\", sep = \"\\t\", quote = \"\\\"\", colClasses = \"character\"))\nlines <- as.numeric(gsub(\"[^0-9]\", \"\", system(\"wc -l ./source_files/PPIData4Expr_noLimit.txt\", intern=T)))\nsize.estimate <- lines / 1000 * top.size\n```\n\nJust reading the file would require about `r size.estimate` bytes of memory, too much in any case. I decide to simplify the file to load it up. \n\n#### Pre-formatting the text-mined dataset\n\nI re-process the dataset by removing the reference sentences, which make up for most of the file size. \nFurther cleaning is required, since there are several UniProtKB accessions, comma-separated, per line. I need to have a single identifier per line in order to generate pair ids. \nFinally, the PMIDs and PMCIDs given in the PMCID field also need to be divided in single line records.\n\nAll tasks are tackled using PERL, which is more efficient than R in this case. \n\n```{r eval=TRUE,cache=TRUE}\nsystem(\"perl ./scripts/field_selector.pl ./source_files/PPIData4Expr_noLimit.txt ./processed_files/PPIData4Expr_sel_fields.txt\")\nsystem(\"rm ./source_files/PPIData4Expr_noLimit.txt\")\nsystem(\"perl ./scripts/multiplier.pl ./processed_files/PPIData4Expr_sel_fields.txt ./processed_files/tm_full.txt\")\nsystem(\"perl ./scripts/multiplier2.pl ./processed_files/tm_full.txt ./processed_files/tm_full_single.txt\")\n```\n\nFile size gets dramatically reduced (5.25 GB to ~94 MB), so it is now manageable and I load it up. \n\n```{r, cache=TRUE}\ntm_full <- read.csv(\"./processed_files/tm_full_single.txt\", sep = \"\\t\", header = T, colClasses=\"character\")\n\nsystem(\"rm ./processed_files/tm_full.txt\")\nsystem(\"rm ./processed_files/tm_full_single.txt\")\n\ntm_full$Nof.Docs <- as.numeric(tm_full$Nof.Docs)\ntm_full$Nof.co.occr.in.Title.Abs <- as.numeric(tm_full$Nof.co.occr.in.Title.Abs)\ntm_full$Nof.co.occr.in.Body <- as.numeric(tm_full$Nof.co.occr.in.Body)\n\ntm_full <- tm_full[order(as.numeric(tm_full$Nof.Docs),decreasing=T),]\n```\n\nNow I generate the pair ids for the text-mined datset.\n\n```{r,cache=TRUE}\ntm_full$pair_id <- apply(tm_full[,1:2], 1,function(i){\n  paste(sort(i),collapse = \"_\")\n})\ntm_full$tm <- 1\n```\n\n#### Exploring the dataset\n\nI do a tentative plot of the data, to see how many pairs, roughly, are represented in just a few publications and how many are represented in many of them. \n\n```{r warning=FALSE,message=FALSE, fig.width=10, fig.height=4}\nlibrary(dplyr)\ntm_full_pair_info <- unique(select(tm_full,pair_id,Nof.Docs,Nof.co.occr.in.Title.Abs,Nof.co.occr.in.Body,tm))\n\nlibrary(ggplot2)\n\ng <- ggplot(data=tm_full_pair_info, aes(tm_full_pair_info$Nof.Docs))\ng <- g + geom_density()\ng <- g + labs(title =\"Publications behind interacting pairs\", y = \"Density of publications\", x= \"Number of publications supporting the interaction\")\n\ng2 <- g + coord_cartesian(ylim = c(0,0.0001))\ng2 <- g2 + labs(title =\"Zoomed to the y axis lowest region\", x = \"Number of publications supporting the interaction\", y=\"\")\n\nmultiplot(g,g2,cols=2)\n\n```\n\nThe graph is not perfect, but it is still informative. I now need to compare the text mining predictions with the IMEx set of interactions. \n\n### Part 2: Comparison with the IMEx dataset\n\n#### Loading the IMEx dataset\n\nI use a small pipeline to put together data from DIP and IntAct. The details can be found [here](https://github.com/pporrasebi/darkspaceproject/IMEx/IMEx_dsgen.md). \n\n```{r}\nimex_full <- read.delim(\"../../darkspaceproject/IMEx/results//imex_full.txt\", header=T, sep=\"\\t\",colClasses=\"character\")\n```\n\nI select exclusively the human data (interactions where both proteins are human). \n\n```{r}\nimex_human <- unique(subset(imex_full,taxid_a==\"9606\" & taxid_b==\"9606\"))\n```\n\n#### Comparison between IMEx and the text-mined dataset at the pair level\n\nI compare both datasets using the pair ids.\n\n```{r warning=FALSE,message=FALSE,comment=NA}\nimex_sel <- unique(select(imex_human,pair_id_clean,pair_id_clean,id_a_clean,id_b_clean,taxid_a,taxid_b,pubid))\nimex_sel$imex <- 1\nimex_pairs <- unique(select(imex_sel, pair_id=pair_id_clean,imex))\n\ncomp <- unique(merge(tm_full_pair_info,imex_pairs,by=\"pair_id\",all=T))\n\ncomp <- mutate(comp, db_pair =\n                 ifelse(tm == 1 & is.na(imex), \"tm\",\n                 ifelse(is.na(tm) & imex == 1, \"imex\",\n                 ifelse(tm == 1 & imex == 1, \"tm & imex\",\n                 \"check\"))))\n\ncomp$db_pair <- as.factor(comp$db_pair)\n\ncomp <- mutate(comp, nr_oc_group =\n               ifelse(Nof.Docs <= 5, Nof.Docs, \"over 5\"))\n\ntable(comp$db_pair,useNA=\"ifany\")\n\ncomp_simple <- unique(select(comp, pair_id,db_pair))\n\nwrite.table(comp_simple,\"./results/pairs_tm_vs_imex.txt\",col.names=T,row.names=F,quote=F,sep=\"\\t\")\n```\n\nThere is some overlap between the datasets when comparing the pairs. I save this file as a temporary output while the issues with the publication count (discussed below) are solved. \n\n#### Comparison between IMEx and the text-mined dataset at the publication level\n\nNow I will check how many of the publications where the pairs have been reported in the text-mined dataset were curated in IMEx. For that I first need to translate the PMC ids given in the PMCIDs field to PMIDs, in order to be able to compare with the IMEx dataset. \n\nFirst I obtain the translation table. \n\n```{r cache=TRUE,eval=TRUE}\nif(!file.exists(\"./source_files/PMID_PMCID_DOI.csv.gz\")){\n  download.file(url=\"ftp://ftp.ebi.ac.uk/pub/databases/pmc/DOI/PMID_PMCID_DOI.csv.gz\", destfile=\"./source_files/PMID_PMCID_DOI.csv.gz\",method=\"curl\")\n}\nlibrary(\"data.table\")\nsystem(\"gunzip ./source_files/PMID_PMCID_DOI.csv.gz\")\n\nmap_pub <- fread(\"./source_files/PMID_PMCID_DOI.csv\",header=T,sep=\",\",stringsAsFactors=F)\nmap_pub_sel <- unique(select(map_pub,PMID,PMCID))\nrm(map_pub)\nsystem(\"rm ./source_files/PMID_PMCID_DOI.csv\")\n```\n\n```{r eval=TRUE,cache=TRUE}\ntm_pmcids <- unique(select(tm_full,PMCIDs))\ntm_pmcids2pmids <- merge(tm_pmcids,map_pub_sel,by.x=\"PMCIDs\",by.y=\"PMCID\",all.x=T,all.y=F)\ntm_pmcids2pmids <- mutate(tm_pmcids2pmids, PMID =\n                 ifelse(is.na(PMID), PMCIDs,\n                 PMID))\nrm(map_pub_sel)\n```\n\nNow I map the pairs to the cleaned-up PMIDs, so can generate a file that can be compared to other datasets. \n\n```{r}\ntm_full_map <- unique(merge(tm_full,tm_pmcids2pmids,by=\"PMCIDs\",all.x=T,all.y=F))\ntm_sel <- unique(select(tm_full_map,pair_id,pmid=PMCIDs,tm,Nof.Docs,Nof.co.occr.in.Title.Abs,Nof.co.occr.in.Body))\nwrite.table(tm_sel,\"./results/pairs_pmids_tm.txt\",col.names=T,row.names=F,quote=F,sep=\"\\t\")\nsystem(\"gzip ./results/pairs_pmids_tm.txt\")\n```\n\n### Part 3: Evaluate occurence of a pair as interaction predictor\n\nGiven the limited overlap, I have a quick look to check if the different parameters counted by SK in the EPMC dataset correlate somehow with their presence in the IMEx dataset. \n\n```{r fig.width=7,fig.height=6}\ntm_vs_imex <- unique(subset(comp, db_pair == \"tm\" | db_pair == \"tm & imex\"))\n\ng3 <- ggplot(data=tm_vs_imex, aes(x=db_pair,y=Nof.Docs))\ng3 <- g3 + geom_violin(aes(fill=db_pair))\ng3 <- g3 + scale_fill_manual(values=c(\"#56B4E9\",\"#E69F00\"),\n                             labels=c(\"Found in IMEx\", \"text-mined only\"))\ng3 <- g3 + scale_y_log10(breaks=c(10,100,1000,10000),\n                         labels=function(n){format(n, scientific = FALSE)})\ng3 <- g3 + labs(title =\"Number of occurrences in EPMC in the IMEx and text-mined groups\", y = \"Number of occurrences (log scale)\", x=\"group\")\ng3 <- g3 + geom_hline(yintercept=median(tm_vs_imex[tm_vs_imex$db_pair == \"tm\",2]), colour=\"#56B4E9\", linetype=\"dashed\")\ng3 <- g3 + geom_hline(yintercept=median(tm_vs_imex[tm_vs_imex$db_pair == \"tm & imex\",2]), colour=\"#E69F00\", linetype=\"dashed\")\ng3 <- g3 + annotate(\"text\", x=0.75, median(tm_vs_imex[tm_vs_imex$db_pair == \"tm\",2])+0.5, label = \"EPMC-only\\nmedian\", colour=\"#56B4E9\")\ng3 <- g3 + annotate(\"text\", x=1.75, median(tm_vs_imex[tm_vs_imex$db_pair == \"tm & imex\",2])+0.7, label = \"Found in IMEx\\nmedian\", colour=\"#E69F00\")\ng3 <- g3 + theme(legend.position=\"none\")\ng3\n```\n\nNow I check the statistical significance of the difference in the number of publications between the set of predicted pairs found in IMEx and the rest. \n\nThe data is clearly non-parametric, I compare if the variances of the two sets are at least similar to decide which test to use. I use the [Bartlett test of homogeneity of variances](https://en.wikipedia.org/wiki/Bartlett's_test). \n\n```{r comment=NA}\nbartlett.test(tm_vs_imex[,2], tm_vs_imex[,8])\n```\nThe null hypothesis of homogeneous variances is rejected, so I decide to use the [Mood test](https://en.wikipedia.org/wiki/Median_test) for comparison of the median of two populations. I have to do the test with a sample of 20000 elements of the text0mined subset, since the fully-sized test throws an error and does not give any results. \n\n```{r comment=NA}\n\nnocs_tm <- sample(tm_vs_imex[tm_vs_imex$db_pair == \"tm\",2], 20000)\nnocs_both <- sample(tm_vs_imex[tm_vs_imex$db_pair == \"tm & imex\",2])\n\nmood.test(nocs_both,nocs_tm,alternative=\"two.sided\")\n\n```\n\nI reject the null hypothesis of identical medians. It seems that pairs represented in IMEx tend to be found in a higher number of publications, we can probably use the number of publications as a criterium to decide which pairs to explore first. \n\n\n\n************************************************************\n\n## Appendix: Keywords describing interaction relationships\n\n - (de)acetylate\n - (co)activate\n - transactivate \n - (dis)associate \n - add ?\n - bind\n - link ?\n - catalyse\n - cleave\n - co(-)immunoprecipitate, co(-)ip\n - (de)methylate\n - (de)phosphorylate\n - (de)phosphorylase\n - produce ?\n - modify\n - impair \n - inactivate \n - inhibit \n - interact\n - react\n - (dis)assemble\n - discharge ?\n - modulate \n - stimulate\n - substitute ?\n - (de)ubiquitinate \n - heterodimerize\n - heterotrimerize \n - immunoprecipitate\n - (co)assemble\n - co-crystal\n - complex\n - copurifies\n - cross-link\n - two(-)hybrid, 2(-)hybrid, 2(-)H, yeast two(-) hybrid, yeast 2(-) hybrid), Y(-)2H, classical two(-)hybrid, classical 2(-) hybrid, Gal4 transcription regeneration\n - cosediment\n - comigrate\n - AP(-)MS\n - TAP-MS\n - Homo (dimer/trimer/tetramer…)\n - Oligomerize\n\n********************************************************\n\n## Appendix 2: Extra code\n\n#### Multiplot function\n\n```{r eval=FALSE}\n# Multiple plot function\n#\n# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)\n# - cols:   Number of columns in layout\n# - layout: A matrix specifying the layout. If present, 'cols' is ignored.\n#\n# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),\n# then plot 1 will go in the upper left, 2 will go in the upper right, and\n# 3 will go all the way across the bottom.\n#\nmultiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {\n  library(grid)\n\n  # Make a list from the ... arguments and plotlist\n  plots <- c(list(...), plotlist)\n\n  numPlots = length(plots)\n\n  # If layout is NULL, then use 'cols' to determine layout\n  if (is.null(layout)) {\n    # Make the panel\n    # ncol: Number of columns of plots\n    # nrow: Number of rows needed, calculated from # of cols\n    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),\n                    ncol = cols, nrow = ceiling(numPlots/cols))\n  }\n\n if (numPlots==1) {\n    print(plots[[1]])\n\n  } else {\n    # Set up the page\n    grid.newpage()\n    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))\n\n    # Make each plot, in the correct location\n    for (i in 1:numPlots) {\n      # Get the i,j matrix positions of the regions that contain this subplot\n      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))\n\n      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,\n                                      layout.pos.col = matchidx$col))\n    }\n  }\n}\n```",
    "created" : 1460560118616.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1695758443",
    "id" : "54D3E02C",
    "lastKnownWriteTime" : 1460626504,
    "path" : "~/Documents/Projects/darkspaceproject2/epmc_text_mining/tm_epmc_tr.Rmd",
    "project_path" : "tm_epmc_tr.Rmd",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}